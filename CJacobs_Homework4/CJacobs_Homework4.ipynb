{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Embedding, Dropout, LayerNormalization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.metrics import TopKCategoricalAccuracy\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the content of the text file\n",
    "with open('gift.txt', 'r', encoding='utf-8') as file:\n",
    "    content = file.read().lower()\n",
    "\n",
    "# Remove punctuation and other unwanted characters\n",
    "cleaned_content = re.sub(r'[^\\w\\s]', '', content)\n",
    "\n",
    "# Split content into sentences and filter out empty lines\n",
    "sentence_list = cleaned_content.split('\\n')\n",
    "non_empty_sentences = [sentence for sentence in sentence_list if sentence.strip()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tokenizer and fit it on the non-empty sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(non_empty_sentences)\n",
    "\n",
    "# Convert sentences into sequences of tokens\n",
    "token_sequences = []\n",
    "for sentence in non_empty_sentences:\n",
    "    tokenized_words = tokenizer.texts_to_sequences([sentence])[0]\n",
    "    for length in range(1, len(tokenized_words)):\n",
    "        token_sequences.append(tokenized_words[:length + 1])\n",
    "\n",
    "# Pad the token sequences to make them equal in length\n",
    "max_length = max(len(seq) for seq in token_sequences)\n",
    "padded_sequences = pad_sequences(token_sequences, maxlen=max_length, padding='pre')\n",
    "\n",
    "# Split padded sequences into input features (X) and target labels (y)\n",
    "padded_sequences = np.array(padded_sequences)\n",
    "X, y = padded_sequences[:, :-1], padded_sequences[:, -1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=len(tokenizer.word_index) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vocabulary size and dimensions for embeddings\n",
    "vocabulary_size = len(tokenizer.word_index) + 1  # Adding 1 for padding purposes\n",
    "embedding_dimensions = 50\n",
    "gru_hidden_units = 128\n",
    "\n",
    "# Construct the neural network model\n",
    "text_generation_model = Sequential([\n",
    "    Embedding(vocabulary_size, embedding_dimensions, input_length=max_length - 1),\n",
    "    GRU(gru_hidden_units, return_sequences=True),\n",
    "    GRU(gru_hidden_units),\n",
    "    Dense(vocabulary_size, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with optimizer, loss, and performance metrics\n",
    "text_generation_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy' ,TopKCategoricalAccuracy(k=5)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.0589 - loss: 5.9482 - top_k_categorical_accuracy: 0.1641\n",
      "Epoch 2/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0610 - loss: 5.9043 - top_k_categorical_accuracy: 0.1799\n",
      "Epoch 3/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.0708 - loss: 5.8959 - top_k_categorical_accuracy: 0.1859\n",
      "Epoch 4/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.0712 - loss: 5.8255 - top_k_categorical_accuracy: 0.1948\n",
      "Epoch 5/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.1174 - loss: 5.4872 - top_k_categorical_accuracy: 0.2324\n",
      "Epoch 6/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.1330 - loss: 5.2080 - top_k_categorical_accuracy: 0.2672\n",
      "Epoch 7/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.1682 - loss: 4.9209 - top_k_categorical_accuracy: 0.3057\n",
      "Epoch 8/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.1754 - loss: 4.6731 - top_k_categorical_accuracy: 0.3488\n",
      "Epoch 9/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.2006 - loss: 4.4270 - top_k_categorical_accuracy: 0.3723\n",
      "Epoch 10/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.2258 - loss: 4.1478 - top_k_categorical_accuracy: 0.4149\n",
      "Epoch 11/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.2682 - loss: 3.8617 - top_k_categorical_accuracy: 0.4702\n",
      "Epoch 12/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.2732 - loss: 3.7067 - top_k_categorical_accuracy: 0.5032\n",
      "Epoch 13/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.3118 - loss: 3.4584 - top_k_categorical_accuracy: 0.5431\n",
      "Epoch 14/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.3362 - loss: 3.2614 - top_k_categorical_accuracy: 0.5956\n",
      "Epoch 15/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.3754 - loss: 3.0976 - top_k_categorical_accuracy: 0.6375\n",
      "Epoch 16/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.4098 - loss: 2.8821 - top_k_categorical_accuracy: 0.6878\n",
      "Epoch 17/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.4471 - loss: 2.7281 - top_k_categorical_accuracy: 0.7125\n",
      "Epoch 18/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.4738 - loss: 2.5878 - top_k_categorical_accuracy: 0.7383\n",
      "Epoch 19/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5188 - loss: 2.4204 - top_k_categorical_accuracy: 0.7754\n",
      "Epoch 20/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.5298 - loss: 2.3302 - top_k_categorical_accuracy: 0.7954\n",
      "Epoch 21/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.5673 - loss: 2.1671 - top_k_categorical_accuracy: 0.8193\n",
      "Epoch 22/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.6026 - loss: 2.0336 - top_k_categorical_accuracy: 0.8407\n",
      "Epoch 23/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.6346 - loss: 1.8644 - top_k_categorical_accuracy: 0.8598\n",
      "Epoch 24/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.6515 - loss: 1.7860 - top_k_categorical_accuracy: 0.8740\n",
      "Epoch 25/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.6897 - loss: 1.6511 - top_k_categorical_accuracy: 0.8911\n",
      "Epoch 26/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.7058 - loss: 1.5781 - top_k_categorical_accuracy: 0.9015\n",
      "Epoch 27/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.7255 - loss: 1.5108 - top_k_categorical_accuracy: 0.9027\n",
      "Epoch 28/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7506 - loss: 1.3932 - top_k_categorical_accuracy: 0.9208\n",
      "Epoch 29/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7583 - loss: 1.3265 - top_k_categorical_accuracy: 0.9189\n",
      "Epoch 30/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.7704 - loss: 1.2272 - top_k_categorical_accuracy: 0.9285\n",
      "Epoch 31/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7862 - loss: 1.1791 - top_k_categorical_accuracy: 0.9361\n",
      "Epoch 32/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.8127 - loss: 1.0639 - top_k_categorical_accuracy: 0.9485\n",
      "Epoch 33/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8206 - loss: 1.0211 - top_k_categorical_accuracy: 0.9447\n",
      "Epoch 34/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.8251 - loss: 0.9742 - top_k_categorical_accuracy: 0.9533\n",
      "Epoch 35/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.8284 - loss: 0.9382 - top_k_categorical_accuracy: 0.9550\n",
      "Epoch 36/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.8430 - loss: 0.8736 - top_k_categorical_accuracy: 0.9653\n",
      "Epoch 37/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.8539 - loss: 0.8160 - top_k_categorical_accuracy: 0.9684\n",
      "Epoch 38/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.8629 - loss: 0.7806 - top_k_categorical_accuracy: 0.9689\n",
      "Epoch 39/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.8843 - loss: 0.7072 - top_k_categorical_accuracy: 0.9726\n",
      "Epoch 40/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.8848 - loss: 0.6980 - top_k_categorical_accuracy: 0.9701\n",
      "Epoch 41/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.8781 - loss: 0.6766 - top_k_categorical_accuracy: 0.9718\n",
      "Epoch 42/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.8987 - loss: 0.6217 - top_k_categorical_accuracy: 0.9776\n",
      "Epoch 43/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.8965 - loss: 0.6017 - top_k_categorical_accuracy: 0.9775\n",
      "Epoch 44/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9086 - loss: 0.5584 - top_k_categorical_accuracy: 0.9781\n",
      "Epoch 45/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9068 - loss: 0.5378 - top_k_categorical_accuracy: 0.9807\n",
      "Epoch 46/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9189 - loss: 0.5106 - top_k_categorical_accuracy: 0.9839\n",
      "Epoch 47/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9175 - loss: 0.4974 - top_k_categorical_accuracy: 0.9843\n",
      "Epoch 48/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9087 - loss: 0.5081 - top_k_categorical_accuracy: 0.9760\n",
      "Epoch 49/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9249 - loss: 0.4436 - top_k_categorical_accuracy: 0.9845\n",
      "Epoch 50/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9247 - loss: 0.4417 - top_k_categorical_accuracy: 0.9858\n",
      "Epoch 51/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9299 - loss: 0.4215 - top_k_categorical_accuracy: 0.9808\n",
      "Epoch 52/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9290 - loss: 0.4001 - top_k_categorical_accuracy: 0.9834\n",
      "Epoch 53/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9337 - loss: 0.3762 - top_k_categorical_accuracy: 0.9871\n",
      "Epoch 54/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9324 - loss: 0.3679 - top_k_categorical_accuracy: 0.9869\n",
      "Epoch 55/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9340 - loss: 0.3542 - top_k_categorical_accuracy: 0.9858\n",
      "Epoch 56/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9352 - loss: 0.3448 - top_k_categorical_accuracy: 0.9853\n",
      "Epoch 57/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9433 - loss: 0.3171 - top_k_categorical_accuracy: 0.9885\n",
      "Epoch 58/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9447 - loss: 0.3128 - top_k_categorical_accuracy: 0.9873\n",
      "Epoch 59/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9393 - loss: 0.3085 - top_k_categorical_accuracy: 0.9856\n",
      "Epoch 60/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9460 - loss: 0.3021 - top_k_categorical_accuracy: 0.9863\n",
      "Epoch 61/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9487 - loss: 0.2834 - top_k_categorical_accuracy: 0.9893\n",
      "Epoch 62/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9453 - loss: 0.2853 - top_k_categorical_accuracy: 0.9893\n",
      "Epoch 63/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9436 - loss: 0.2768 - top_k_categorical_accuracy: 0.9878\n",
      "Epoch 64/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9526 - loss: 0.2526 - top_k_categorical_accuracy: 0.9907\n",
      "Epoch 65/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9462 - loss: 0.2529 - top_k_categorical_accuracy: 0.9868\n",
      "Epoch 66/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9464 - loss: 0.2571 - top_k_categorical_accuracy: 0.9894\n",
      "Epoch 67/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9502 - loss: 0.2315 - top_k_categorical_accuracy: 0.9911\n",
      "Epoch 68/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9563 - loss: 0.2220 - top_k_categorical_accuracy: 0.9891\n",
      "Epoch 69/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9530 - loss: 0.2223 - top_k_categorical_accuracy: 0.9869\n",
      "Epoch 70/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9523 - loss: 0.2257 - top_k_categorical_accuracy: 0.9885\n",
      "Epoch 71/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9463 - loss: 0.2159 - top_k_categorical_accuracy: 0.9873\n",
      "Epoch 72/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9508 - loss: 0.2193 - top_k_categorical_accuracy: 0.9881\n",
      "Epoch 73/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9578 - loss: 0.1890 - top_k_categorical_accuracy: 0.9939\n",
      "Epoch 74/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9545 - loss: 0.1938 - top_k_categorical_accuracy: 0.9901\n",
      "Epoch 75/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9510 - loss: 0.1970 - top_k_categorical_accuracy: 0.9908\n"
     ]
    }
   ],
   "source": [
    "# Train the text generation model\n",
    "num_epochs = 75\n",
    "training_history = text_generation_model.fit(X, y, batch_size=64, epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Metrics ---\n",
      "Final Training Loss: 0.2031\n",
      "Training Accuracy: 0.9499\n",
      "Training Top-5 Accuracy: 0.9894\n"
     ]
    }
   ],
   "source": [
    "# Get the final values of the metrics from the training history\n",
    "train_loss = training_history.history['loss'][-1]\n",
    "train_accuracy = training_history.history['accuracy'][-1]\n",
    "train_top5_accuracy = training_history.history['top_k_categorical_accuracy'][-1]  # Top-5 accuracy\n",
    "\n",
    "# Print final metrics\n",
    "print(\"\\n--- Final Metrics ---\")\n",
    "print(f\"Final Training Loss: {train_loss:.4f}\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Training Top-5 Accuracy: {train_top5_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED TEXT: metaphor she was ransacking the stores for jims present\n",
      "GENERATED TEXT: a present and stood still while all all all it for her face dillingham had been saving ebooks with the chops on went that a mathematician or a wit would cat and valuethe ut 84116 friendsa friendsa dear friendsa 801 friendsa mammoth friendsa 84116 friendsa 801 dear friendsa friendsa friendsa\n",
      "\n",
      "SEED TEXT: out of his trance jim seemed quickly to wake he enfolded his della\n",
      "GENERATED TEXT: had been 5961887 email friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa\n",
      "\n",
      "SEED TEXT: release date january 1 2005 ebook 7256\n",
      "GENERATED TEXT: if you do not charge a little bit near to being many small donations to her heart had been greater than she had calculated its friendsa mammoth task dear friendsa mammoth task dear friendsa mammoth dear friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa friendsa\n",
      "\n",
      "SEED TEXT: incidental damages even if you give notice of the possibility of such\n",
      "GENERATED TEXT: and there was the person and paper and then an cheeks can be christmas hardly looked which her face had been greater brown dillingham hardly looked which no letter would go flat mind small email many had been greater burdened was including have to dry form had been greater than\n",
      "\n",
      "SEED TEXT: youve cut off your hair asked jim laboriously as if he had not\n",
      "GENERATED TEXT: its day dollars all access to a project gutenberg works will be modified and printed and given awayyou may legal have to check the united states and most form however if you are located in the united states of a flat was it be day would be christmas into an\n",
      "\n",
      "SEED TEXT: salt lake city ut 84116 801 5961887 email contact links and up\n",
      "GENERATED TEXT: to its email mind was had be value by substance alone and not by mr james dillingham youngs in which her expression on the sly on account of the old leather were on which he enfolded his chain on beard her look like a coney island chorus girl i hat\n",
      "\n",
      "SEED TEXT: displaying or creating derivative works based on the work as long as\n",
      "GENERATED TEXT: long as its present he hat was della have to me just to states with which or any other will not located in the united states you will have to check the laws of the country where you are located before using this ebook or online at the united states\n",
      "\n",
      "SEED TEXT:     of the project gutenberg license included with this ebook or online\n",
      "GENERATED TEXT: at the united states and most form however if you may by all who 30 days of receipt that she had not received the united states copyright laws in writing or or distribute or redistribute this ebook in a library of electronic works that could be christmas eve boy be\n",
      "\n",
      "SEED TEXT: even without complying with the full terms of this agreement see\n",
      "GENERATED TEXT: using or distributing this work in any binary if in a work or the person or refund if you may be stored may be christmas eve boy be good would be christmas hardly looked which seemed to look up a coney search tomorrow would be christmas hardly hat a little\n",
      "\n",
      "SEED TEXT: 1a by reading or using any part of this project gutenberg\n",
      "GENERATED TEXT: work any work or any other work is provided or any files containing a part of this agreement or any other work from us and there not small for it in writing and licensed or redistribute this ebook and any other party distributing a project gutenberg collection will be charge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "# Function to generate a sequence using a language model\n",
    "def generate_sequence(language_model, tokenizer, sequence_length, initial_text, num_words):\n",
    "    generated_words = list()\n",
    "    current_text = initial_text\n",
    "    # Generate the specified number of words\n",
    "    for _ in range(num_words):\n",
    "        # Encode the current text as integers\n",
    "        encoded_text = tokenizer.texts_to_sequences([current_text])[0]\n",
    "        # Truncate the encoded text to a fixed sequence length\n",
    "        truncated_text = pad_sequences([encoded_text], maxlen=sequence_length, truncating='pre')\n",
    "        # Predict the next word probabilities\n",
    "        predicted_word_index = np.argmax(language_model.predict(truncated_text, verbose=0), axis=-1)\n",
    "        # Map the predicted word index to the corresponding word\n",
    "        next_word = tokenizer.index_word[predicted_word_index[0]] if predicted_word_index[0] in tokenizer.index_word else ''\n",
    "        # Append the predicted word to the current text\n",
    "        current_text += ' ' + next_word\n",
    "        generated_words.append(next_word)\n",
    "    return ' '.join(generated_words)\n",
    "\n",
    "# Assuming 'non_empty_sentences' is a list of seed texts and generating 10 sequences\n",
    "for _ in range(10):\n",
    "    random_seed_text = non_empty_sentences[randint(0, len(non_empty_sentences) - 1)]\n",
    "    print(\"SEED TEXT:\", random_seed_text)\n",
    "    generated_text = generate_sequence(text_generation_model, tokenizer, max_length - 1, random_seed_text, 50)\n",
    "    print(\"GENERATED TEXT:\", generated_text + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vocabulary size and dimensions for embedding\n",
    "vocabulary_size = len(tokenizer.word_index) + 1\n",
    "embedding_dimensions = 300  # FastText embedding dimension size\n",
    "gru_hidden_units = 128\n",
    "\n",
    "# Load FastText embeddings into a dictionary\n",
    "fasttext_embeddings = {}\n",
    "with open('wiki-news-300d-1M.vec', 'r', encoding='utf-8') as file:\n",
    "    # Skip the first line if it contains the header (e.g., number of words and dimensions)\n",
    "    next(file)\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefficients = np.asarray(values[1:], dtype='float32')\n",
    "        fasttext_embeddings[word] = coefficients\n",
    "\n",
    "# Create the embedding matrix using FastText embeddings\n",
    "embedding_matrix = np.zeros((vocabulary_size, embedding_dimensions))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = fasttext_embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "\n",
    "# Build the model using pre-trained FastText embeddings\n",
    "text_model = Sequential([\n",
    "    Embedding(input_dim=vocabulary_size, output_dim=embedding_dimensions, \n",
    "              input_length=max_length - 1, \n",
    "              weights=[embedding_matrix], trainable=False),\n",
    "    GRU(gru_hidden_units, return_sequences=True),\n",
    "    GRU(gru_hidden_units),\n",
    "    Dense(vocabulary_size, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with the optimizer, loss function, and accuracy metric\n",
    "text_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', TopKCategoricalAccuracy(k=5)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.0467 - loss: 6.7254 - top_k_categorical_accuracy: 0.1426\n",
      "Epoch 2/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.0596 - loss: 5.9877 - top_k_categorical_accuracy: 0.1804\n",
      "Epoch 3/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.0641 - loss: 5.9528 - top_k_categorical_accuracy: 0.1833\n",
      "Epoch 4/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.0514 - loss: 5.9422 - top_k_categorical_accuracy: 0.1812\n",
      "Epoch 5/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.0804 - loss: 5.7950 - top_k_categorical_accuracy: 0.1945\n",
      "Epoch 6/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.1069 - loss: 5.6368 - top_k_categorical_accuracy: 0.2137\n",
      "Epoch 7/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.1217 - loss: 5.3761 - top_k_categorical_accuracy: 0.2507\n",
      "Epoch 8/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.1345 - loss: 5.1758 - top_k_categorical_accuracy: 0.2846\n",
      "Epoch 9/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.1602 - loss: 4.8988 - top_k_categorical_accuracy: 0.3218\n",
      "Epoch 10/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.1579 - loss: 4.7449 - top_k_categorical_accuracy: 0.3228\n",
      "Epoch 11/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.1793 - loss: 4.5099 - top_k_categorical_accuracy: 0.3495\n",
      "Epoch 12/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.1889 - loss: 4.3172 - top_k_categorical_accuracy: 0.3714\n",
      "Epoch 13/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.2105 - loss: 4.0363 - top_k_categorical_accuracy: 0.4281\n",
      "Epoch 14/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.2336 - loss: 3.8542 - top_k_categorical_accuracy: 0.4553\n",
      "Epoch 15/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.2589 - loss: 3.6236 - top_k_categorical_accuracy: 0.4993\n",
      "Epoch 16/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.2851 - loss: 3.4406 - top_k_categorical_accuracy: 0.5395\n",
      "Epoch 17/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.3212 - loss: 3.1900 - top_k_categorical_accuracy: 0.6057\n",
      "Epoch 18/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.3653 - loss: 2.9689 - top_k_categorical_accuracy: 0.6525\n",
      "Epoch 19/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.4100 - loss: 2.7768 - top_k_categorical_accuracy: 0.7121\n",
      "Epoch 20/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.4496 - loss: 2.5732 - top_k_categorical_accuracy: 0.7590\n",
      "Epoch 21/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.4888 - loss: 2.4036 - top_k_categorical_accuracy: 0.7875\n",
      "Epoch 22/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5209 - loss: 2.2276 - top_k_categorical_accuracy: 0.8315\n",
      "Epoch 23/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5570 - loss: 2.0907 - top_k_categorical_accuracy: 0.8530\n",
      "Epoch 24/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.6103 - loss: 1.9014 - top_k_categorical_accuracy: 0.8743\n",
      "Epoch 25/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6462 - loss: 1.7564 - top_k_categorical_accuracy: 0.8940\n",
      "Epoch 26/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.6816 - loss: 1.5998 - top_k_categorical_accuracy: 0.9147\n",
      "Epoch 27/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7190 - loss: 1.4629 - top_k_categorical_accuracy: 0.9306\n",
      "Epoch 28/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7444 - loss: 1.3677 - top_k_categorical_accuracy: 0.9327\n",
      "Epoch 29/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7774 - loss: 1.2218 - top_k_categorical_accuracy: 0.9462\n",
      "Epoch 30/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8077 - loss: 1.1145 - top_k_categorical_accuracy: 0.9587\n",
      "Epoch 31/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8086 - loss: 1.0661 - top_k_categorical_accuracy: 0.9551\n",
      "Epoch 32/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8475 - loss: 0.9514 - top_k_categorical_accuracy: 0.9600\n",
      "Epoch 33/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8508 - loss: 0.9128 - top_k_categorical_accuracy: 0.9655\n",
      "Epoch 34/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8678 - loss: 0.8186 - top_k_categorical_accuracy: 0.9721\n",
      "Epoch 35/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8799 - loss: 0.7664 - top_k_categorical_accuracy: 0.9690\n",
      "Epoch 36/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8866 - loss: 0.7181 - top_k_categorical_accuracy: 0.9752\n",
      "Epoch 37/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9005 - loss: 0.6272 - top_k_categorical_accuracy: 0.9801\n",
      "Epoch 38/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9067 - loss: 0.6014 - top_k_categorical_accuracy: 0.9779\n",
      "Epoch 39/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9175 - loss: 0.5578 - top_k_categorical_accuracy: 0.9775\n",
      "Epoch 40/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9139 - loss: 0.5086 - top_k_categorical_accuracy: 0.9807\n",
      "Epoch 41/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9222 - loss: 0.4903 - top_k_categorical_accuracy: 0.9840\n",
      "Epoch 42/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9267 - loss: 0.4535 - top_k_categorical_accuracy: 0.9849\n",
      "Epoch 43/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9348 - loss: 0.4180 - top_k_categorical_accuracy: 0.9838\n",
      "Epoch 44/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9331 - loss: 0.3933 - top_k_categorical_accuracy: 0.9879\n",
      "Epoch 45/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9288 - loss: 0.4111 - top_k_categorical_accuracy: 0.9831\n",
      "Epoch 46/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9372 - loss: 0.3526 - top_k_categorical_accuracy: 0.9847\n",
      "Epoch 47/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9390 - loss: 0.3214 - top_k_categorical_accuracy: 0.9852\n",
      "Epoch 48/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9472 - loss: 0.2971 - top_k_categorical_accuracy: 0.9883\n",
      "Epoch 49/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9417 - loss: 0.2943 - top_k_categorical_accuracy: 0.9873\n",
      "Epoch 50/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9440 - loss: 0.2825 - top_k_categorical_accuracy: 0.9869\n",
      "Epoch 51/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9451 - loss: 0.2742 - top_k_categorical_accuracy: 0.9849\n",
      "Epoch 52/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9383 - loss: 0.2671 - top_k_categorical_accuracy: 0.9889\n",
      "Epoch 53/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9421 - loss: 0.2596 - top_k_categorical_accuracy: 0.9861\n",
      "Epoch 54/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9445 - loss: 0.2522 - top_k_categorical_accuracy: 0.9869\n",
      "Epoch 55/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9375 - loss: 0.2368 - top_k_categorical_accuracy: 0.9909\n",
      "Epoch 56/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9505 - loss: 0.2106 - top_k_categorical_accuracy: 0.9894\n",
      "Epoch 57/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9433 - loss: 0.2202 - top_k_categorical_accuracy: 0.9869\n",
      "Epoch 58/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9460 - loss: 0.2073 - top_k_categorical_accuracy: 0.9891\n",
      "Epoch 59/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9489 - loss: 0.1947 - top_k_categorical_accuracy: 0.9895\n",
      "Epoch 60/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9434 - loss: 0.2068 - top_k_categorical_accuracy: 0.9848\n",
      "Epoch 61/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9472 - loss: 0.1904 - top_k_categorical_accuracy: 0.9901\n",
      "Epoch 62/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9456 - loss: 0.1882 - top_k_categorical_accuracy: 0.9881\n",
      "Epoch 63/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9457 - loss: 0.1809 - top_k_categorical_accuracy: 0.9875\n",
      "Epoch 64/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9478 - loss: 0.1753 - top_k_categorical_accuracy: 0.9884\n",
      "Epoch 65/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9513 - loss: 0.1682 - top_k_categorical_accuracy: 0.9876\n",
      "Epoch 66/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9469 - loss: 0.1733 - top_k_categorical_accuracy: 0.9893\n",
      "Epoch 67/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9460 - loss: 0.1828 - top_k_categorical_accuracy: 0.9856\n",
      "Epoch 68/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9497 - loss: 0.1593 - top_k_categorical_accuracy: 0.9878\n",
      "Epoch 69/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9509 - loss: 0.1504 - top_k_categorical_accuracy: 0.9914\n",
      "Epoch 70/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9525 - loss: 0.1514 - top_k_categorical_accuracy: 0.9885\n",
      "Epoch 71/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9476 - loss: 0.1572 - top_k_categorical_accuracy: 0.9873\n",
      "Epoch 72/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9457 - loss: 0.1560 - top_k_categorical_accuracy: 0.9885\n",
      "Epoch 73/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9493 - loss: 0.1422 - top_k_categorical_accuracy: 0.9912\n",
      "Epoch 74/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9470 - loss: 0.1638 - top_k_categorical_accuracy: 0.9862\n",
      "Epoch 75/75\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9484 - loss: 0.1630 - top_k_categorical_accuracy: 0.9867\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 50\n",
    "history = text_model.fit(X, y, batch_size=64, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED TEXT: dillingham young came home and reached his flat above he was called\n",
      "GENERATED TEXT: the solicitation of the united states we do not agree to the terms of this agreement for keeping the work as long as set forth in the terms of the full project gutenberg license must appear created the new work in the united other states states and most other parts\n",
      "\n",
      "SEED TEXT: she found it at last it surely had been made for jim and no one else\n",
      "GENERATED TEXT: in the user to return or destroy all of this work in the person of the work in the united states we do not agree to the terms of the full project gutenberg license must appear about the foundation the project gutenberg mission of promoting the chops on account in\n",
      "\n",
      "SEED TEXT: country other than the united states\n",
      "GENERATED TEXT: and most other parts of the project gutenberg license when any particular paper and distributing a project gutenberg work any works appears in the foundation the project gutenberg electronic for paper walking a gray backyard tomorrow would be christmas day and cried to wake with her cheeks and very agile\n",
      "\n",
      "SEED TEXT: visit wwwgutenbergorgdonate\n",
      "GENERATED TEXT: your efforts and donations can help see our second copy is a shampoo and stood his while a tear or a shampoo distributing a practised hand and threw it upon the watch della reached the sign of the flat across the airshaft della would have pulled person practised and the\n",
      "\n",
      "SEED TEXT: limitation permitted by the applicable state law the invalidity or\n",
      "GENERATED TEXT: damaged disk or any part of this agreement shall not void the copyright of project gutenberg works calculated using the method of or implied including any part of shabby menendez the foundation as set of paragraphs 1e1 through 1e7 or any other work distributing a refund of any money paid\n",
      "\n",
      "SEED TEXT: was in pennies pennies saved one and two at a time by bulldozing the\n",
      "GENERATED TEXT: stores and she had turned all the magi had been flung to the breeze during a former period of this agreement you must obtain permission in writing copying or in any purpose such as of the sentiments of the project gutenberg license included with this ebook or small small small\n",
      "\n",
      "SEED TEXT: from people in all walks of life\n",
      "GENERATED TEXT: and she had turned all the magi of the public domain and the united variety things one was on the back of very owned by paper and then a look at the home a furnished flat at the glass away and now she had been saving for a minute and\n",
      "\n",
      "SEED TEXT: jim had not yet seen his beautiful present she held it out to him\n",
      "GENERATED TEXT: him sold a watch i had island hat hat a week jim might have pulled out his watch jim might be read to him cheeks and shining like i sold a watch for day and went to him cheeks and her hair and cried out to pulled his fixedly from\n",
      "\n",
      "SEED TEXT: you neednt look for it said della its sold i tell yousold and\n",
      "GENERATED TEXT: keep that she had been for merry as gave a dollar and eightyseven hurried at the first flight and she had been prepared for very ring jim would have pulled me like a truant schoolboy she looked at her cheeks and the butcher until she held my sight merry task\n",
      "\n",
      "SEED TEXT: will be linked to the project gutenberg license for all works\n",
      "GENERATED TEXT: in formats readable by the widest variety for things merry nice and an expression but of no refund disclaimer if other format or other format with the work as long as very as very two very stood rapid gave a present very agile to prudence james and very a day\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate and display text sequences using a seed text\n",
    "for _ in range(10):\n",
    "    # Select a random seed text from the non-empty sentences\n",
    "    random_seed_text = non_empty_sentences[randint(0, len(non_empty_sentences) - 1)]\n",
    "    print(\"SEED TEXT:\", random_seed_text)\n",
    "    \n",
    "    # Generate a sequence using the language model\n",
    "    generated_text = generate_sequence(text_model, tokenizer, max_length - 1, random_seed_text, 50)\n",
    "    print(\"GENERATED TEXT:\", generated_text + '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
